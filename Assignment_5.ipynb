{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a31cb7b-5463-41b8-89f3-80c97826bbb4",
   "metadata": {
    "id": "7a31cb7b-5463-41b8-89f3-80c97826bbb4"
   },
   "source": [
    "## Problem Statement 7\n",
    "### Implement the Continuous Bag of Words (CBOW) Model for the given (textual document 2) using the below steps:\n",
    "    a. Data preparation\n",
    "    b. Generate training data\n",
    "    c. Train model\n",
    "    d. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548f4fd4-7443-4cc7-b95d-4c76df89b18c",
   "metadata": {
    "id": "548f4fd4-7443-4cc7-b95d-4c76df89b18c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical  # instead of np_utils\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2684cca7-618b-4922-b0f3-d483bdecd75e",
   "metadata": {
    "id": "2684cca7-618b-4922-b0f3-d483bdecd75e"
   },
   "outputs": [],
   "source": [
    "data=\"\"\"But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness. No one rejects, dislikes, or avoids pleasure itself, because it is pleasure, but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful. Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?\"\"\"\n",
    "\n",
    "dl_data=data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2a2e4-6fd5-47e7-bae0-acd04bca3a50",
   "metadata": {
    "id": "47a2a2e4-6fd5-47e7-bae0-acd04bca3a50"
   },
   "source": [
    "## a. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1ad1f1-6fff-4828-8c1e-31580ca9e043",
   "metadata": {
    "id": "ed1ad1f1-6fff-4828-8c1e-31580ca9e043"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dl_data)\n",
    "\n",
    "words2id = tokenizer.word_index\n",
    "words2id['PAD']=0\n",
    "\n",
    "id2words = {v:k for k,v in words2id.items()}\n",
    "\n",
    "wids = [[words2id[w] for w in text.text_to_word_sequence(doc)] for doc in dl_data]\n",
    "\n",
    "vocab_size=len(words2id)\n",
    "embed_size=100\n",
    "window_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1929a8fa-c3c6-416b-a283-725f239241b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1929a8fa-c3c6-416b-a283-725f239241b4",
    "outputId": "1dd840b3-083b-4225-c732-e0227654d771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  102\n",
      "Vocabulary items:  [('to', 1), ('of', 2), ('pleasure', 3), ('pain', 4), ('a', 5), ('the', 6), ('who', 7), ('but', 8), ('and', 9), ('or', 10)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: \", vocab_size)\n",
    "print(\"Vocabulary items: \", list(words2id.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a202f40-f7fc-4351-96ce-efeb2be2b16b",
   "metadata": {
    "id": "1a202f40-f7fc-4351-96ce-efeb2be2b16b"
   },
   "source": [
    "## b. Generating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a181c722-8bbd-4c3e-ada1-ac6a7298936c",
   "metadata": {
    "id": "a181c722-8bbd-4c3e-ada1-ac6a7298936c"
   },
   "outputs": [],
   "source": [
    "def pairwise(corpus, window_size, vocab_size):\n",
    "    context_length=window_size*2\n",
    "\n",
    "    for words in corpus:\n",
    "        sentence_length=len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words=[]\n",
    "            label_word=[]\n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "\n",
    "            context_words.append([words[i]\n",
    "                                 for i in range(start, end)\n",
    "                                 if 0 <= i < sentence_length\n",
    "                                 and i != index])\n",
    "            label_word.append(word)\n",
    "\n",
    "            x = pad_sequences(context_words, maxlen=context_length)\n",
    "            y = to_categorical(label_word, vocab_size)\n",
    "            yield(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf5938-a1b4-4dce-ac6f-0cf05087ae00",
   "metadata": {
    "id": "f4cf5938-a1b4-4dce-ac6f-0cf05087ae00"
   },
   "source": [
    "## c. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f5fa08-deee-48ca-85dc-a5e6ae5e700c",
   "metadata": {
    "id": "99f5fa08-deee-48ca-85dc-a5e6ae5e700c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur_vc1xnom\\Desktop\\LP4\\dlenv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cbow = Sequential()\n",
    "\n",
    "cbow.add(Embedding(input_dim = vocab_size, output_dim = embed_size, input_length = window_size * 2))\n",
    "cbow.add(Lambda(lambda x:K.mean(x, axis = 1), output_shape=(embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "cbow.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4b3f3a-ce4f-49ac-ba7c-d345b4bb1a36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "6b4b3f3a-ce4f-49ac-ba7c-d345b4bb1a36",
    "outputId": "21a214d8-0425-4c3c-df78-8df646305d2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cbow.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e26938-c8a4-4d58-be02-897a213b15eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3e26938-c8a4-4d58-be02-897a213b15eb",
    "outputId": "61c8a666-7cff-4114-a37a-0e95b69136a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000149D40B4AE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000149D40B4AE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch: 1 Loss: 772.9935841560364\n",
      "\n",
      "Epoch: 2 Loss: 769.6444368362427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,3):\n",
    "    loss=0\n",
    "\n",
    "    for x,y in pairwise(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch,loss))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785e035d-882e-4942-b565-048bc5402274",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "785e035d-882e-4942-b565-048bc5402274",
    "outputId": "637d4392-5c15-4403-8876-b37f06f93381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.040641</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.045073</td>\n",
       "      <td>-0.042532</td>\n",
       "      <td>0.039772</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>-0.022964</td>\n",
       "      <td>-0.024844</td>\n",
       "      <td>-0.035216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039629</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>-0.039055</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>-0.045233</td>\n",
       "      <td>-0.011630</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>-0.039132</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.027502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pleasure</th>\n",
       "      <td>0.023873</td>\n",
       "      <td>0.033676</td>\n",
       "      <td>-0.034842</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>-0.031948</td>\n",
       "      <td>-0.024719</td>\n",
       "      <td>-0.026599</td>\n",
       "      <td>-0.028809</td>\n",
       "      <td>0.015129</td>\n",
       "      <td>0.037716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039123</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>-0.024683</td>\n",
       "      <td>-0.006513</td>\n",
       "      <td>-0.008650</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.040352</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>0.040286</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.038814</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>-0.025471</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.037355</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>-0.033676</td>\n",
       "      <td>-0.009741</td>\n",
       "      <td>0.021619</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>-0.043634</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.012385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.040206</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.048137</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>-0.016166</td>\n",
       "      <td>-0.042422</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.039826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045830</td>\n",
       "      <td>0.037929</td>\n",
       "      <td>-0.047885</td>\n",
       "      <td>-0.029244</td>\n",
       "      <td>-0.022886</td>\n",
       "      <td>-0.040069</td>\n",
       "      <td>-0.004594</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.049407</td>\n",
       "      <td>-0.010357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.047279</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>-0.021031</td>\n",
       "      <td>-0.029547</td>\n",
       "      <td>-0.024062</td>\n",
       "      <td>0.049753</td>\n",
       "      <td>-0.017282</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>-0.006096</td>\n",
       "      <td>0.027492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025104</td>\n",
       "      <td>-0.011023</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>-0.032624</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>-0.017754</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>-0.026512</td>\n",
       "      <td>0.024815</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5   \\\n",
       "of        0.040641  0.011549  0.045073 -0.042532  0.039772  0.040936   \n",
       "pleasure  0.023873  0.033676 -0.034842  0.013925 -0.031948 -0.024719   \n",
       "pain      0.040286  0.011894  0.038814  0.047646  0.001465 -0.025471   \n",
       "a        -0.040206  0.035498  0.027908  0.017308  0.048137  0.023147   \n",
       "the      -0.047279  0.022679 -0.021031 -0.029547 -0.024062  0.049753   \n",
       "\n",
       "                6         7         8         9   ...        90        91  \\\n",
       "of        0.038031 -0.022964 -0.024844 -0.035216  ... -0.039629  0.033493   \n",
       "pleasure -0.026599 -0.028809  0.015129  0.037716  ... -0.039123  0.039247   \n",
       "pain      0.001414  0.029952  0.018181  0.020947  ...  0.007485  0.037355   \n",
       "a        -0.016166 -0.042422  0.007062  0.039826  ...  0.045830  0.037929   \n",
       "the      -0.017282  0.038298 -0.006096  0.027492  ... -0.025104 -0.011023   \n",
       "\n",
       "                92        93        94        95        96        97  \\\n",
       "of       -0.039055  0.049727 -0.045233 -0.011630  0.041958 -0.039132   \n",
       "pleasure  0.007857  0.036693 -0.024683 -0.006513 -0.008650  0.010335   \n",
       "pain      0.003129 -0.033676 -0.009741  0.021619 -0.019041 -0.043634   \n",
       "a        -0.047885 -0.029244 -0.022886 -0.040069 -0.004594 -0.000144   \n",
       "the       0.003730 -0.032624  0.021004 -0.017754  0.014316 -0.026512   \n",
       "\n",
       "                98        99  \n",
       "of       -0.031351 -0.027502  \n",
       "pleasure  0.040352  0.016129  \n",
       "pain      0.037323  0.012385  \n",
       "a         0.049407 -0.010357  \n",
       "the       0.024815  0.000801  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = cbow.get_weights()[0]\n",
    "weights = weights[1:]\n",
    "print(weights.shape)\n",
    "\n",
    "pd.DataFrame(weights, index=list(id2words.values())[1:]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac16b55-feae-462b-a3c6-47d58a0284a8",
   "metadata": {
    "id": "dac16b55-feae-462b-a3c6-47d58a0284a8"
   },
   "source": [
    "## d. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b47d7c0-0132-45d9-ace3-e79d9780b261",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b47d7c0-0132-45d9-ace3-e79d9780b261",
    "outputId": "73b75939-dcb5-4464-ef9d-b4f82aec3b15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 101)\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = euclidean_distances(weights)\n",
    "print(distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f14c45-0153-4d59-81b5-2834c23a3c65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5f14c45-0153-4d59-81b5-2834c23a3c65",
    "outputId": "2d5f3bf0-4bc9-4690-c31f-89a44a9481c0"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " mistaken\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mistaken': ['this', 'denouncing', 'avoids', 'nor', 'no', 'painful']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inwords = input()\n",
    "\n",
    "similar_words={ search_term: [id2words[idx] for idx in distance_matrix[words2id[search_term]-1].argsort()[0:6]]\n",
    "              for search_term in {inwords}}\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef7d46-5411-4feb-95b1-eaaba3ebde4a",
   "metadata": {
    "id": "a6ef7d46-5411-4feb-95b1-eaaba3ebde4a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
